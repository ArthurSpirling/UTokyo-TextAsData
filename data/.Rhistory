str(job999866covars_chameleons)
source('~/GitHub/sophistication/analysis_article/BT_new_ling_covs_May8.R')
prop.correct(BTT)
summary(BTT)
source('~/GitHub/sophistication/analysis_article/BT_new_ling_covs_May8.R')
source('~/GitHub/sophistication/analysis_article/BT_new_ling_covs_May8.R')
source('~/GitHub/sophistication/analysis_article/BT_new_ling_covs_May8.R')
source('~/GitHub/sophistication/analysis_article/BT_new_ling_covs_May8.R')
str(job999866covars_chameleons)
source('~/GitHub/sophistication/analysis_article/BT_new_ling_covs_May8.R')
source('~/GitHub/sophistication/analysis_article/BT_new_ling_covs_May8.R')
colnames(job999866covars_chameleons$predictors)
source('~/GitHub/sophistication/analysis_article/BT_new_ling_covs_May8.R')
BTT <- BTm(player1=easier, player2=harder,
formula=~
+brown_min[ID]
+n_adverb[ID],
id="ID",  data=job999866covars_chameleons)
print(prop.correct(BTT))
?BTm
help("chameleons")
source('~/GitHub/sophistication/analysis_article/BT_new_ling_covs_May8.R')
print(summary(BTT))
?make_input_bt
?bt_input_make
source('~/GitHub/sophistication/analysis_article/BT_new_ling_covs_May8.R')
source('C:/projects/Hansard/markov/dataoverviews/BIGmodel.R')
A <- function(r){pi*(r**2)}
A(1:10)
plot(1:10, A(1:10))
x11()
plot(1:10, A(1:10))
require(readtext)
rm(list=ls())
start.time <- Sys.time()
require(quanteda)
require(sophistication)
require(BradleyTerry2)
require(VSURF)
load("data/R_intermediate/job999866covars_chameleons.rdata")
dat <- job999866covars_chameleons
end.time <- Sys.time()
print(time.taken <- end.time - start.time)
time.taken/60
time.taken
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/make_topic_plot.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/make_topic_plot.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/make_topic_plot.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/make_topic_plot_male_vs_female.R')
?barplot
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/make_topic_plot_male_vs_female.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/make_topic_plot_male_vs_female.R')
?text
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/make_topic_plot_male_vs_female.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/make_topic_plot_male_vs_female.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/make_topic_plot_male_vs_female.R')
install.packages("wordcloud")
require(wordcloud)
comparison.cloud(term.matrix,scale=c(4,.5),max.words=300,
random.order=FALSE,rot.per=.1,
colors=brewer.pal(ncol(term.matrix),"Dark2"),
use.r.layout=FALSE,title.size=3,...)
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
warnings()
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
require(tm)
data(SOTU)
corp <- SOTU
corp <- tm_map(corp, removePunctuation)
corp <- tm_map(corp, content_transformer(tolower))
corp <- tm_map(corp, removeNumbers)
corp <- tm_map(corp, function(x)removeWords(x,stopwords()))
term.matrix <- TermDocumentMatrix(corp)
term.matrix <- as.matrix(term.matrix)
colnames(term.matrix) <- c("SOTU 2010","SOTU 2011")
wordcloud(term.matrix)
require(wordcloud)
require(quanteda)
mydfm <- dfm(data_char_ukimmig2010, remove = c("will", stopwords("english")),
remove_punct = TRUE)
require(wordcloud)
require(quanteda)
mydfm <- dfm(data_char_ukimmig2010, remove = c("will", stopwords("english")),
remove_punct = TRUE)
myCorpus <- corpus(data_char_ukimmig2010)
myCorpus <- corpus(data_char_ukimmig2010)
mydfm <- dfm(myCorpus, remove = c("will", stopwords("english")),
remove_punct = TRUE)
myCorpus <- corpus(data_char_ukimmig2010)
dfm(myCorpus)
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
?dfm
mydfm <- dfm(myCorpus, remove=stopwords())
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
?dfm
mydfm <- dfm(myCorpus, remove=stopwords(), remove_punct=T)
mydfm <- dfm(myCorpus, remove=stopwords(), remove_punct=TRUE)
mydfm <- dfm(myCorpus, remove=stopwords("english"), remove_punct=TRUE)
testText <- "The quick brown fox named Seamus jumps over the lazy dog also named Seamus, with
the newspaper from a boy named Seamus, in his mouth."
testCorpus <- corpus(testText)
# note: "also" is not in the default stopwords("english")
featnames(dfm(testCorpus, select = stopwords("english")))
textplot_wordcloud(mydfm, min.freq = 6, random.order = FALSE,
rot.per = .25,
colors = RColorBrewer::brewer.pal(8,"Dark2"))
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
mydfm <- dfm(myCorpus, remove=stopwords("english"), remove_punct=TRUE)
mydfm <- dfm(data_char_ukimmig2010, remove = c("will", stopwords("english")),
remove_punct = TRUE)
devtools::install_github("kbenoit/quanteda")
require(quanteda)
myCorpus <- corpus(data_char_ukimmig2010)
mydfm <- dfm(myCorpus, remove=stopwords("english"), remove_punct=TRUE)
mydfm <- dfm(myCorpus, remove_punct=TRUE)
require(quanteda)
myCorpus <- corpus(data_char_ukimmig2010)
mydfm <- dfm(myCorpus, remove_punct=TRUE)
require(quanteda)
myCorpus <- corpus(data_char_ukimmig2010)
mydfm <- dfm(myCorpus, remove_punct=TRUE)
dfm("This: contains punctuation.", remove_punct = TRUE)
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
mydfm <- dfm(myCorpus)
mydfm
?dfm
mydfm <- dfm(myCorpus, remove_punct=TRUE)
?dfm
?dfm
?quanteda::dfm
?quanteda::dfm
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
?dfm
txt <- c("This is software testing: looking for (word) pairs the dog! peas and carrots",
"This [is] a software testing again. For. the dog want the book peas and carrots ",
"Here: this is more Software Testing, want the book looking again for word pairs. peas and carrots ")
x <- !TRUE
quanteda::dfm(txt, stem = FALSE, verbose = FALSE, remove_numbers = FALSE, remove_punct = TRUE)
install.packages("quanteda")
require(wordcloud)
require(quanteda)
myCorpus <- corpus(data_char_ukimmig2010)
mydfm <- dfm(myCorpus, remove_punct=TRUE)
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
myCorpus
summary(myCorpus)
myCorpus[1]
myCorpus[8]
myCorpus[6]
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
?texplot_wordcloud
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
?wordcloud
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
?box
textplot_wordcloud(all, min.freq = 3, max.words=20, random.order = FALSE,
rot.per = .25,
colors = "darkblue")
text(0,0,"X=1")
x11()
#separate, bnp v libdems
par(mfrow=c(1,2))
textplot_wordcloud(bnp, min.freq = 6, max.words=20, random.order = FALSE,
rot.per = .25,
colors = "darkblue")
text(1,1,"X=0")
box()
textplot_wordcloud(ld, min.freq = 3, max.words=20, random.order = FALSE,
rot.per = .25,
colors = "darkblue")
text(1,1,"X=1")
box()
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
?text
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('C:/Users/as9934/Dropbox/Text_As_Data_Spring2017/code/draw_word_distributions_by_covariate.R')
source('~/GitHub/sophistication/analysis_article/BT_VSURF_ling_cov_May19.R')
source('C:/Users/as9934/Dropbox/Japan_Text_Class/code/day2_part2.R')
basic_pca
DFM
DFM<-as.matrix( dfm(manifestos_corpus) )
basic_pca<-prcomp(DFM)
basic_pca
source('C:/Users/as9934/Dropbox/Japan_Text_Class/code/day2_part2.R')
basic_pca
DFM<- dfm(manifestos_corpus)
#do basic psa - note we have to transpose the matrix
basic_pca<-prcomp(t(as.matrix(DFM)))
basic_pca
basic_pca[,1]
str(basic_pca)
basic_pca$rotation
basic_pca$rotation[,1]
x11()
screeplot(basic_pca)
#let's grab that first PCA and plot it
first.pca <- basic_pca$rotation[,1]
x11()
#let's plot them over time
dates <- as.numeric( gsub('[^[:digit:]]','',docnames(manifestos_corpus)) )
plot(dates, first.pca)
#make sure points are colored intutiively
#grab party names
ps <- gsub("[0-9].*", "", rownames(mds))
cols <- ps #make color vector
cols[cols=="Con"] <- 'blue'
cols[cols=="Lib"] <- 'gold'
cols[cols=='Lab'] <- 'red'
rownames(first.pca)
rownames(DFM)
ps <- gsub("[0-9].*", "", rownames(DFM))
cols <- ps #make color vector
cols[cols=="Con"] <- 'blue'
cols[cols=="Lib"] <- 'gold'
cols[cols=='Lab'] <- 'red'
#let's plot them over time
dates <- as.numeric( gsub('[^[:digit:]]','',docnames(manifestos_corpus)) )
plot(dates, first.pca, col=cols)
#let's plot them over time
dates <- as.numeric( gsub('[^[:digit:]]','',docnames(manifestos_corpus)) )
plot(dates, first.pca, col=cols, pch=16, cex=2)
hclust
dist.matrix <- dist(DFM)
dist.matrix
hclust(dist.matrix)
plot(hclust(dist.matrix))
textmodel_wordfish()
?textmodel_wordfish()
wordfish.model <- textmodel_wordfish(DFM)
wordfish.model
plot(wordfish.model)
textplot_scaled(wordfish.model)
textplot_scal1d(wordfish.model)
textplot_scale1d(wordfish.model)
install.packages("austin")
textplot_scal1d(wordfish.model)
textplot_scale1d(wordfish.model)
rownames(DFM)
wordfish.model <- textmodel_wordfish(DFM, dir=c(42,19))
textplot_scale1d(wordfish.model)
wordfish.model
rownames(DFM)[42]
rownames(DFM)[19]
rownames(DFM)
DFM2 <- DFM[c(8:23),c(31:46),]
rownames(DFM2)
DFM2 <- DFM[c(8:23, 31:46),]
rownames(DFM2)
DFM2 <- DFM[c(8:23, 31:46),]
wordfish.model2 <- textmodel_wordfish(DFM2, dir=c(28,12))
textplot_scale1d(wordfish.model2)
summary(wordfish.model2)
str(wordfish.model2
str(wordfish.model2)
words<-wordfish.model2@psi
names(words) <- wordfish.model2@features
sort(words, decreasing=T)[1:50]
DFM<- dfm(manifestos_corpus, remove_Punct=TRUE)
?dfm
DFM<- dfm(manifestos_corpus, remove_punct=TRUE)
basic_pca<-prcomp(t(as.matrix(DFM)))
#looks like first PC does most of the lifting
x11()
screeplot(basic_pca)
#let's grab that first PCA and plot it
first.pca <- basic_pca$rotation[,1]
x11()
first.pca <- basic_pca$rotation[,1]
x11()
#make sure points are colored intutiively
#grab party names
ps <- gsub("[0-9].*", "", rownames(DFM))
cols <- ps #make color vector
cols[cols=="Con"] <- 'blue'
cols[cols=="Lib"] <- 'gold'
cols[cols=='Lab'] <- 'red'
#let's plot them over time
dates <- as.numeric( gsub('[^[:digit:]]','',docnames(manifestos_corpus)) )
plot(dates, first.pca, col=cols, pch=16, cex=2)
dist.matrix <- dist(DFM)
x11()
plot( hclust(dist.matrix) )
wordfish.model <- textmodel_wordfish(DFM, dir=c(42,19))
#let's take a look at 1d model results
textplot_scale1d(wordfish.model)
DFM2 <- DFM[c(8:23, 31:46),]
wordfish.model2 <- textmodel_wordfish(DFM2, dir=c(28,12))
textplot_scale1d(wordfish.model2)
words<-wordfish.model2@psi
names(words) <- wordfish.model2@features
sort(words, decreasing=T)[1:15]
wordfish.model2@beta
weights <- wordfish.model2@beta
names(weights) <- wordfish.model2@features
weights
print(head(sort(weights)))
print(tail(sort(weights)))
print(head(sort(weights), 10))
print(tail(sort(weights), 10))
plot(weights, fixed.effects)
fixed.effects <- wordfish.model2@psi
names(fixed.effects) <- wordfish.model2@features
sort(fixed.effects, decreasing=T)[1:15]
#let's look at word weights (betas)
weights <- wordfish.model2@beta
names(weights) <- wordfish.model2@features
#let's get the biggest and smallest ones
print(head(sort(weights), 10))
print(tail(sort(weights), 10))
plot(weights, fixed.effects)
install.packages("topicmodels")
?FindTopicsNumber
install.packages("ldatuning")
library(topicmodels)
library(ldatuning)
how.many.topics <- FindTopicsNumber(DFM2,  topics = seq(from = 2, to = 30, by = 1))
lda
LDA
?LDA
lda.model <- LDA(DFM2, k=10)
ptm <- proc.time()
lda.model <- LDA(DFM2, k=10)
print( proc.time() - ptm )
topicProbabilities <- as.data.frame(lda.model@gamma) #rows are docs, columns are topics
topicProbabilities
topicProbabilities[,1]
rowSums(topicProbabilities)
termassignments <- as.data.frame(t(posterior(lda.model)$terms))
termassignments
rownames(termassignments)
barplot(termassignments["taxation",])
termassignments["taxation",]
as.vector(termassignments["taxation",])
barplot(as.vector(termassignments["taxation",]))
as.vector(termassignments["taxation",])
as.numeric(termassignments["taxation",])
barplot(as.numeric(termassignments["taxation",]))
barplot(as.numeric(termassignments["1919",]))
topTerms <- terms(lda.model, 6)
topTerms
DFM3 <- dfm(DFM2)
DFM3 <- dfm(DFM2, remove=c(stopwords()))
DFM3
DFM2
DFM3 <- dfm(DFM2, remove=c(stopwords()))
lda.model <- LDA(DFM3, k=10)
topicProbabilities <- as.data.frame(lda.model@gamma)
topicProbabilities
termassignments <- as.data.frame(t(posterior(lda.model)$terms))
termassignments
x11()
par(mfrow=c(1,2))
barplot(as.numeric(termassignments["taxation",])) #everywhere
barplot(as.numeric(termassignments["1919",])) #one place
topTerms <- terms(lda.model, 6)
topTerms
proc.time()
ptm<-proc.time()
proc.time() - ptm
ptm <- proc.time()
how.many.topics <- FindTopicsNumber(DFM3,  topics = seq(from = 2, to = 6, by = 1))
time.taken <- proc.time() - ptm
time.taken
how.many.topics
plot(how.many.topics)
FindTopicsNumber_plot(how.many.topics)
?FindTopicsNumber
ptm <- proc.time()
how.many.topics <- FindTopicsNumber(DFM3,  topics = seq(from = 2, to = 8, by = 1))
time.taken <- proc.time() - ptm
#plot the result (larger number is better in this metric)
x11()
FindTopicsNumber_plot(how.many.topics)
time.taken
ptm <- proc.time()
how.many.topics <- FindTopicsNumber(DFM3,  topics = seq(from = 2, to = 15, by = 1))
time.taken <- proc.time() - ptm
FindTopicsNumber_plot(how.many.topics)
time.taken
487/60
rm(list=ls())
setwd("C:/Users/as9934/Dropbox/Japan_Text_Class/data/")
#################
#Getting Started#
#################
#install quanteda and readtext
library(quanteda)
library(readtext)
#let's grab the UK manifestos and create a corpus
manifestos <- readtext("UK_manifestos/*.txt", docvarsfrom=c("filenames"))
manifestos_corpus <- corpus(manifestos)
#and let's grab SOTU too
sotu_corpus <- corpus(readtext("sotu/*.txt",docvarsfrom=c("filenames")) )
#we'll also need ldadtuning and topicmodels, later
library(topicmodels)
library(ldatuning)
#make a dfm
DFM<- dfm(manifestos_corpus, remove_punct=TRUE)
#do basic psa - note we have to transpose the matrix
basic_pca<-prcomp(t(as.matrix(DFM)))
#looks like first PC does most of the lifting
x11()
screeplot(basic_pca)
#let's grab that first PCA and plot it
first.pca <- basic_pca$rotation[,1]
x11()
#make sure points are colored intutiively
#grab party names
ps <- gsub("[0-9].*", "", rownames(DFM))
cols <- ps #make color vector
cols[cols=="Con"] <- 'blue'
cols[cols=="Lib"] <- 'gold'
cols[cols=='Lab'] <- 'red'
#let's plot them over time
dates <- as.numeric( gsub('[^[:digit:]]','',docnames(manifestos_corpus)) )
plot(dates, first.pca, col=cols, pch=16, cex=2)
#some overtime variation...
#...but doesn't seem to be a v good ideological measurement!
#patterns we see in pca, we often see in clustering...
dist.matrix <- dist(DFM)
x11()
plot( hclust(dist.matrix) )
#looks fairly time series-y
# Con1992 look like an outlier for some reason
wordfish.model <- textmodel_wordfish(DFM, dir=c(42,19))
#let's take a look at 1d model results
textplot_scale1d(wordfish.model)
#hmm, looks a time series effect
#maybe this is an artifact of Liberal manifestos
#let's redo, just using post war Lab and Con ones
DFM2 <- DFM[c(8:23, 31:46),]
wordfish.model2 <- textmodel_wordfish(DFM2, dir=c(28,12))
textplot_scale1d(wordfish.model2)
#hmm, still looks very time series dependent
#(note that quanteda will drop a bunch of terms not in new DFM)
# let's look at the word fixed effects
# recall that words with high fixed effects are used a lot
# ... but need not be informative
fixed.effects <- wordfish.model2@psi
names(fixed.effects) <- wordfish.model2@features
sort(fixed.effects, decreasing=T)[1:15]
#let's look at word weights (betas)
weights <- wordfish.model2@beta
names(weights) <- wordfish.model2@features
#let's get the biggest and smallest ones
print(head(sort(weights), 10))
print(tail(sort(weights), 10))
#not particularly informative!  might want to get rid of numbers!
fixed.effects <- wordfish.model2@psi
names(fixed.effects) <- wordfish.model2@features
sort(fixed.effects, decreasing=T)[1:15]
#let's look at word weights (betas)
weights <- wordfish.model2@beta
names(weights) <- wordfish.model2@features
#let's get the biggest and smallest ones
print(head(sort(weights), 10))
print(tail(sort(weights), 10))
#not particularly informative!  might want to get rid of numbers!
#'eiffel tower' plot
x11()
plot(weights, fixed.effects)
#we'll just work with the Labour and Conservative post-war data
#we'll be a little more aggressive about preprocessing -- get rid of stopwords too
DFM3 <- dfm(DFM2, remove=c(stopwords()))
lda.model <- LDA(DFM3, k=10)
topicProbabilities <- as.data.frame(lda.model@gamma)
topicProbabilities
#now, let's grab the terms and see what topic they were assigned to
termassignments <- as.data.frame(t(posterior(lda.model)$terms))
#for example, what topic(s) would we expect to find words in
x11()
par(mfrow=c(1,2))
barplot(as.numeric(termassignments["taxation",])) #everywhere
barplot(as.numeric(termassignments["1919",])) #one place
topTerms <- terms(lda.model, 6)
topTerms
how.many.topics <- FindTopicsNumber(DFM3,  topics = seq(from = 2, to = 15, by = 1))
x11()
FindTopicsNumber_plot(how.many.topics)
